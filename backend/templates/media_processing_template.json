{
  "app": {
    "name": "Media Processing App",
    "description": "A generic app for camera and image processing operations.",
    "theme": "light"
  },
  "layout": {
    "type": "singlepage",
    "regions": ["header", "main", "footer"]
  },
  "components": [
    {
      "id": "app-header",
      "type": "container",
      "region": "header",
      "styles": {
        "backgroundColor": "#3498db",
        "color": "#fff",
        "padding": "10px",
        "textAlign": "center",
        "marginBottom": "20px"
      },
      "children": [
        {
          "id": "app-title",
          "type": "text",
          "properties": {
            "text": "Media Processing App",
            "variant": "h1"
          },
          "styles": {
            "fontSize": "2em",
            "fontWeight": "bold",
            "textShadow": "2px 2px 4px #000000"
          }
        }
      ]
    },
    {
      "id": "media-container",
      "type": "container",
      "region": "main",
      "styles": {
        "width": "90%",
        "margin": "0 auto",
        "border": "2px solid #3498db",
        "borderRadius": "10px",
        "padding": "20px",
        "backgroundColor": "#f8f9fa"
      },
      "children": [
        {
          "id": "media-view",
          "type": "container",
          "styles": {
            "width": "100%",
            "height": "480px",
            "backgroundColor": "#000",
            "marginBottom": "20px",
            "position": "relative",
            "overflow": "hidden",
            "borderRadius": "8px"
          },
          "children": [
            {
              "id": "video-element",
              "type": "video",
              "properties": {
                "useCamera": false,
                "facingMode": "user",
                "width": "100%",
                "height": "100%",
                "autoPlay": false,
                "muted": true,
                "controls": false
              },
              "styles": {
                "width": "100%",
                "height": "100%",
                "objectFit": "cover",
                "borderRadius": "8px"
              }
            },
            {
              "id": "overlay-canvas",
              "type": "canvas",
              "properties": {
                "overlayFor": "video-element",
                "transparent": true
              },
              "styles": {
                "position": "absolute",
                "top": "0",
                "left": "0",
                "width": "100%",
                "height": "100%",
                "pointerEvents": "none"
              }
            }
          ]
        },
        {
          "id": "controls-container",
          "type": "container",
          "styles": {
            "display": "flex",
            "justifyContent": "center",
            "marginBottom": "20px",
            "gap": "10px",
            "flexWrap": "wrap"
          },
          "children": [
            {
              "id": "start-camera-btn",
              "type": "button",
              "properties": {
                "text": "Start Camera",
                "disabled": "false"
              },
              "styles": {
                "backgroundColor": "#2ecc71",
                "color": "white",
                "border": "none",
                "padding": "10px 16px",
                "borderRadius": "4px",
                "cursor": "pointer",
                "fontWeight": "bold"
              },
              "methods": {
                "onClick": "async function(event, $m) {\n  try {\n    // Access the camera using mediaUtils\n    const constraints = {\n      video: {\n        facingMode: 'user',\n        width: { ideal: 1280 },\n        height: { ideal: 720 }\n      },\n      audio: false\n    };\n    \n    const stream = await navigator.mediaDevices.getUserMedia(constraints);\n    \n    // Get the video element and set the stream\n    const video = document.getElementById('video-element');\n    if (video) {\n      video.srcObject = stream;\n      video.play();\n      $m('#status-text').setValue('Camera active');\n    }\n  } catch (error) {\n    console.error('Error accessing camera:', error);\n    $m('#status-text').setValue('Error: ' + error.message);\n  }\n}"
              }
            },
            {
              "id": "stop-camera-btn",
              "type": "button",
              "properties": {
                "text": "Stop Camera",
                "disabled": "false"
              },
              "styles": {
                "backgroundColor": "#e74c3c",
                "color": "white",
                "border": "none",
                "padding": "10px 16px",
                "borderRadius": "4px",
                "cursor": "pointer",
                "fontWeight": "bold"
              },
              "methods": {
                "onClick": "function(event, $m) {\n  const video = document.getElementById('video-element');\n  if (video && video.srcObject) {\n    // Stop all tracks in the stream\n    const stream = video.srcObject;\n    if (stream instanceof MediaStream) {\n      const tracks = stream.getTracks();\n      tracks.forEach(track => track.stop());\n    }\n    \n    // Clear the source\n    video.srcObject = null;\n    video.pause();\n    \n    // Clear the canvas overlay\n    const canvas = document.getElementById('overlay-canvas');\n    if (canvas) {\n      const ctx = canvas.getContext('2d');\n      if (ctx) {\n        ctx.clearRect(0, 0, canvas.width, canvas.height);\n      }\n    }\n    \n    $m('#status-text').setValue('Camera stopped');\n  }\n}"
              }
            },
            {
              "id": "capture-image-btn",
              "type": "button",
              "properties": {
                "text": "Capture Image",
                "disabled": "false"
              },
              "styles": {
                "backgroundColor": "#3498db",
                "color": "white",
                "border": "none",
                "padding": "10px 16px",
                "borderRadius": "4px",
                "cursor": "pointer",
                "fontWeight": "bold"
              },
              "methods": {
                "onClick": "function(event, $m) {\n  // Get the video element\n  const video = document.getElementById('video-element');\n  if (!video || video.paused || video.ended) {\n    $m('#status-text').setValue('No active video stream to capture');\n    return;\n  }\n  \n  try {\n    // Create a canvas to capture the image\n    const canvas = document.createElement('canvas');\n    canvas.width = video.videoWidth;\n    canvas.height = video.videoHeight;\n    \n    // Draw the current video frame to the canvas\n    const ctx = canvas.getContext('2d');\n    if (ctx) {\n      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n      \n      // Convert to data URL\n      const imageDataUrl = canvas.toDataURL('image/jpeg', 0.9);\n      \n      // Store the captured image URL\n      $m('#captured-image').setProperty('src', imageDataUrl);\n      \n      // Show the captured image\n      $m('#captured-image').setStyle('display', 'block');\n      $m('#status-text').setValue('Image captured');\n    }\n  } catch (error) {\n    console.error('Error capturing image:', error);\n    $m('#status-text').setValue('Error capturing image');\n  }\n}"
              }
            },
            {
              "id": "analyze-btn",
              "type": "button",
              "properties": {
                "text": "Analyze Image",
                "disabled": "false"
              },
              "styles": {
                "backgroundColor": "#9b59b6",
                "color": "white",
                "border": "none",
                "padding": "10px 16px",
                "borderRadius": "4px",
                "cursor": "pointer",
                "fontWeight": "bold"
              },
              "methods": {
                "onClick": "function(event, $m) {\n  // Get the video element and overlay canvas\n  const video = document.getElementById('video-element');\n  const canvas = document.getElementById('overlay-canvas');\n  \n  if (!video || !canvas) return;\n  \n  // Get the 2D context of the canvas\n  const ctx = canvas.getContext('2d');\n  if (!ctx) return;\n  \n  // Make sure the canvas dimensions match the video dimensions\n  const rect = video.getBoundingClientRect();\n  canvas.width = rect.width;\n  canvas.height = rect.height;\n  \n  // Clear previous drawings\n  ctx.clearRect(0, 0, canvas.width, canvas.height);\n  \n  // For demonstration, we'll create a detection zone in the center\n  const detectionWidth = canvas.width / 3;\n  const detectionHeight = canvas.height / 3;\n  const x = (canvas.width - detectionWidth) / 2;\n  const y = (canvas.height - detectionHeight) / 2;\n  \n  // Draw detection rectangle\n  ctx.strokeStyle = 'rgba(46, 204, 113, 0.8)';\n  ctx.lineWidth = 3;\n  ctx.strokeRect(x, y, detectionWidth, detectionHeight);\n  \n  // Add a label\n  ctx.fillStyle = 'rgba(0, 0, 0, 0.7)';\n  ctx.fillRect(x, y - 30, 140, 25);\n  ctx.fillStyle = 'white';\n  ctx.font = '16px Arial';\n  ctx.fillText('Detection Region', x + 10, y - 12);\n  \n  $m('#status-text').setValue('Analysis complete');\n  $m('#analysis-result').setValue('Object detected at center of frame (demonstration)');\n}"
              }
            },
            {
              "id": "clear-btn",
              "type": "button",
              "properties": {
                "text": "Clear Overlay",
                "disabled": "false"
              },
              "styles": {
                "backgroundColor": "#95a5a6",
                "color": "white",
                "border": "none",
                "padding": "10px 16px",
                "borderRadius": "4px",
                "cursor": "pointer",
                "fontWeight": "bold"
              },
              "methods": {
                "onClick": "function(event, $m) {\n  const canvas = document.getElementById('overlay-canvas');\n  if (canvas) {\n    const ctx = canvas.getContext('2d');\n    if (ctx) {\n      ctx.clearRect(0, 0, canvas.width, canvas.height);\n      $m('#status-text').setValue('Overlay cleared');\n    }\n  }\n}"
              }
            }
          ]
        },
        {
          "id": "processing-options",
          "type": "container",
          "styles": {
            "display": "flex",
            "justifyContent": "center",
            "marginBottom": "20px",
            "gap": "20px",
            "flexWrap": "wrap"
          },
          "children": [
            {
              "id": "process-grayscale-btn",
              "type": "button",
              "properties": {
                "text": "Grayscale",
                "disabled": "false"
              },
              "styles": {
                "backgroundColor": "#34495e",
                "color": "white",
                "border": "none",
                "padding": "8px 14px",
                "borderRadius": "4px",
                "cursor": "pointer"
              },
              "methods": {
                "onClick": "function(event, $m) {\n  const video = document.getElementById('video-element');\n  const canvas = document.getElementById('overlay-canvas');\n  \n  if (!video || !canvas) return;\n  \n  const ctx = canvas.getContext('2d');\n  if (!ctx) return;\n  \n  // Set canvas dimensions\n  canvas.width = video.videoWidth || video.clientWidth;\n  canvas.height = video.videoHeight || video.clientHeight;\n  \n  // Draw the current video frame\n  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n  \n  // Get the image data\n  const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);\n  const data = imageData.data;\n  \n  // Apply grayscale filter\n  for (let i = 0; i < data.length; i += 4) {\n    const avg = (data[i] + data[i + 1] + data[i + 2]) / 3;\n    data[i] = data[i + 1] = data[i + 2] = avg;\n  }\n  \n  // Put the modified image data back\n  ctx.putImageData(imageData, 0, 0);\n  \n  $m('#status-text').setValue('Grayscale filter applied');\n}"
              }
            },
            {
              "id": "process-invert-btn",
              "type": "button",
              "properties": {
                "text": "Invert Colors",
                "disabled": "false"
              },
              "styles": {
                "backgroundColor": "#2c3e50",
                "color": "white",
                "border": "none",
                "padding": "8px 14px",
                "borderRadius": "4px",
                "cursor": "pointer"
              },
              "methods": {
                "onClick": "function(event, $m) {\n  const video = document.getElementById('video-element');\n  const canvas = document.getElementById('overlay-canvas');\n  \n  if (!video || !canvas) return;\n  \n  const ctx = canvas.getContext('2d');\n  if (!ctx) return;\n  \n  // Set canvas dimensions\n  canvas.width = video.videoWidth || video.clientWidth;\n  canvas.height = video.videoHeight || video.clientHeight;\n  \n  // Draw the current video frame\n  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n  \n  // Get the image data\n  const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);\n  const data = imageData.data;\n  \n  // Apply invert filter\n  for (let i = 0; i < data.length; i += 4) {\n    data[i] = 255 - data[i];         // red\n    data[i + 1] = 255 - data[i + 1]; // green\n    data[i + 2] = 255 - data[i + 2]; // blue\n  }\n  \n  // Put the modified image data back\n  ctx.putImageData(imageData, 0, 0);\n  \n  $m('#status-text').setValue('Colors inverted');\n}"
              }
            },
            {
              "id": "process-edge-btn",
              "type": "button",
              "properties": {
                "text": "Edge Detection",
                "disabled": "false"
              },
              "styles": {
                "backgroundColor": "#16a085",
                "color": "white",
                "border": "none",
                "padding": "8px 14px",
                "borderRadius": "4px",
                "cursor": "pointer"
              },
              "methods": {
                "onClick": "function(event, $m) {\n  const video = document.getElementById('video-element');\n  const canvas = document.getElementById('overlay-canvas');\n  \n  if (!video || !canvas) return;\n  \n  const ctx = canvas.getContext('2d');\n  if (!ctx) return;\n  \n  // Set canvas dimensions\n  canvas.width = video.videoWidth || video.clientWidth;\n  canvas.height = video.videoHeight || video.clientHeight;\n  \n  // Draw the current video frame\n  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n  \n  // Get the image data\n  const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);\n  const data = imageData.data;\n  const width = canvas.width;\n  const height = canvas.height;\n  \n  // Create a copy of the image data\n  const origData = new Uint8ClampedArray(data);\n  \n  // Simple edge detection using a convolution\n  for (let y = 1; y < height - 1; y++) {\n    for (let x = 1; x < width - 1; x++) {\n      const idx = (y * width + x) * 4;\n      \n      // Get brightness of surrounding pixels\n      const tl = (origData[((y-1) * width + (x-1)) * 4] + \n                  origData[((y-1) * width + (x-1)) * 4 + 1] + \n                  origData[((y-1) * width + (x-1)) * 4 + 2]) / 3;\n      \n      const tr = (origData[((y-1) * width + (x+1)) * 4] + \n                  origData[((y-1) * width + (x+1)) * 4 + 1] + \n                  origData[((y-1) * width + (x+1)) * 4 + 2]) / 3;\n      \n      const bl = (origData[((y+1) * width + (x-1)) * 4] + \n                  origData[((y+1) * width + (x-1)) * 4 + 1] + \n                  origData[((y+1) * width + (x-1)) * 4 + 2]) / 3;\n      \n      const br = (origData[((y+1) * width + (x+1)) * 4] + \n                  origData[((y+1) * width + (x+1)) * 4 + 1] + \n                  origData[((y+1) * width + (x+1)) * 4 + 2]) / 3;\n      \n      // Calculate edge intensity with a simple gradient\n      const edge = Math.abs(tl - br) + Math.abs(tr - bl);\n      \n      // Set edge to white if above threshold, otherwise black\n      const threshold = 30;\n      const val = edge > threshold ? 255 : 0;\n      \n      data[idx] = val;     // Red\n      data[idx + 1] = val; // Green\n      data[idx + 2] = val; // Blue\n    }\n  }\n  \n  // Put the modified image data back\n  ctx.putImageData(imageData, 0, 0);\n  \n  $m('#status-text').setValue('Edge detection applied');\n}"
              }
            }
          ]
        },
        {
          "id": "status-display",
          "type": "container",
          "styles": {
            "display": "flex",
            "flexDirection": "column",
            "gap": "10px",
            "marginBottom": "20px"
          },
          "children": [
            {
              "id": "status-text",
              "type": "text",
              "properties": {
                "text": "Ready",
                "variant": "div"
              },
              "styles": {
                "backgroundColor": "#2c3e50",
                "color": "white",
                "padding": "10px",
                "textAlign": "center",
                "borderRadius": "4px",
                "fontWeight": "bold"
              }
            },
            {
              "id": "analysis-result",
              "type": "text",
              "properties": {
                "text": "No analysis data",
                "variant": "div"
              },
              "styles": {
                "padding": "10px",
                "backgroundColor": "#ecf0f1",
                "borderRadius": "4px",
                "textAlign": "center"
              }
            }
          ]
        },
        {
          "id": "output-container",
          "type": "container",
          "styles": {
            "marginTop": "20px",
            "padding": "10px",
            "border": "1px solid #ddd",
            "borderRadius": "4px",
            "backgroundColor": "#f9f9f9"
          },
          "children": [
            {
              "id": "output-title",
              "type": "text",
              "properties": {
                "text": "Captured Image:",
                "variant": "h3"
              },
              "styles": {
                "textAlign": "center",
                "marginBottom": "10px"
              }
            },
            {
              "id": "captured-image",
              "type": "container",
              "styles": {
                "width": "100%",
                "height": "300px",
                "backgroundSize": "contain",
                "backgroundPosition": "center",
                "backgroundRepeat": "no-repeat",
                "border": "1px solid #ddd",
                "display": "none"
              }
            }
          ]
        }
      ],
      "methods": {
        "onMount": "function($m) {\n  // Wait for the DOM to be fully loaded\n  setTimeout(() => {\n    // Set initial status\n    $m('#status-text').setValue('Ready - Click \"Start Camera\" to begin');\n    \n    // Check for camera support\n    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {\n      $m('#status-text').setValue('Error: Camera not supported by this browser');\n      $m('#start-camera-btn').setProperty('disabled', 'true');\n    }\n    \n    // Add event listener for when the page is closed\n    window.addEventListener('beforeunload', () => {\n      // Stop any active camera stream\n      const video = document.getElementById('video-element');\n      if (video && video.srcObject) {\n        const stream = video.srcObject;\n        if (stream instanceof MediaStream) {\n          const tracks = stream.getTracks();\n          tracks.forEach(track => track.stop());\n        }\n      }\n    });\n  }, 500);\n}"
      }
    },
    {
      "id": "app-footer",
      "type": "container",
      "region": "footer",
      "styles": {
        "backgroundColor": "#3498db",
        "color": "#fff",
        "padding": "10px",
        "textAlign": "center",
        "marginTop": "20px"
      },
      "children": [
        {
          "id": "footer-text",
          "type": "text",
          "properties": {
            "text": "© 2023 Media Processing App",
            "variant": "div"
          },
          "styles": {
            "fontSize": "0.8em"
          }
        }
      ]
    }
  ]
} 