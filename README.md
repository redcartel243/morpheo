# Morpheo - AI-Driven UI Generation Framework

Morpheo is an experimental framework designed to empower Large Language Models (LLMs) like Google's Gemini Pro to dynamically generate web application UIs and logic based on natural language prompts.

**The core principle of Morpheo is: No Hardcoded Domain-Specific Logic.** The framework provides generic building blocks and patterns, but all application-specific behavior, component selection, configuration, and interaction logic must be determined and generated by the AI.

## Core Principles

Morpheo development adheres to the following fundamental principles:

1.  **AI-Driven Generation**: The AI analyzes requests, determines the required UI structure and behavior, selects appropriate components, and defines their interactions.
2.  **Generic Component System**: Components are designed as universal, reusable building blocks (e.g., inputs, buttons, layout containers) applicable across any domain. No component should be tied to a specific use case (e.g., no `WeatherWidget` or `BitcoinChart`).
3.  **Pattern-Based Development**: Focus is on teaching the AI reusable *patterns* for building UIs and handling interactions, rather than implementing specific features directly into the framework.
4.  **Flexibility & AI Creativity**: The framework aims to provide tools and guidance to the AI without unnecessarily constraining its ability to generate novel solutions.

## How it Works (Conceptual)

1.  **User Prompt**: A user provides a natural language description of the desired UI or functionality.
2.  **AI Interaction**: The Morpheo frontend sends the prompt (along with context about available generic components and patterns) to the configured LLM (e.g., Gemini Pro).
3.  **AI Response**: The AI returns instructions detailing which components to use, their properties, layout, and the JavaScript logic needed for interactions and dynamic behavior.
4.  **Dynamic Rendering**: The Morpheo frontend interprets the AI's instructions, renders the specified generic components, and attaches the generated event handlers and logic.

## Tech Stack

*   **Frontend**: HTML, CSS, JavaScript (potentially using a minimal library like React for rendering, but components themselves remain generic)
*   **AI Model**: Google Gemini Pro (or other capable LLM) via API calls.
*   **Core Logic**: Custom JavaScript for interpreting AI responses, managing the component lifecycle, handling events based on AI instructions, and interacting with the DOM (e.g., via the `$m()` utility).
*   **Hosting/Backend (Optional)**: Firebase (or similar) can be used for hosting the static frontend, user authentication, or potentially simple backend functions *if* needed to support the AI interaction or manage user state, but not for core UI generation logic.

## Development Philosophy

Development efforts focus on:

*   Improving the generic capabilities and flexibility of core components.
*   Enhancing the framework's ability to interpret and execute AI instructions safely and efficiently.
*   Refining the prompts and patterns provided to the AI to improve the quality and reliability of generated UIs.
*   **Strictly avoiding** the introduction of any domain-specific logic or components into the core framework.

## Project Structure (Example)

*   **frontend-new/**: Contains the main frontend application code, including generic components, core AI interaction logic, and styling.
    *   `src/components/`: Generic UI building blocks.
    *   `src/core/`: Core logic for AI interaction, rendering, event handling.
    *   `src/utils/`: Utility functions (e.g., `$m()`).
*   *(Adjust this section based on the actual current structure)*

## Getting Started

### Prerequisites

*   Node.js (e.g., v18+)
*   Access to a Gemini Pro API key (or other configured LLM API key)
*   Firebase account (if using Firebase for hosting/auth)

### Installation & Setup

1.  Clone the repository:
    ```bash
    git clone <repository-url> # Replace with your repo URL
    cd morpheo
    ```
2.  Navigate to the frontend directory:
    ```bash
    cd frontend-new
    ```
3.  Install dependencies:
    ```bash
    npm install
    ```
4.  Configure environment variables:
    *   Create a `.env` file in the `frontend-new` directory (you can copy/rename `.env.example` if it exists).
    *   Add your AI API key (e.g., `REACT_APP_GEMINI_API_KEY=your_api_key`).
    *   Add necessary Firebase configuration variables if using Firebase:
        ```
        REACT_APP_FIREBASE_API_KEY=your_firebase_api_key
        REACT_APP_FIREBASE_AUTH_DOMAIN=your_firebase_auth_domain
        REACT_APP_FIREBASE_PROJECT_ID=your_firebase_project_id
        REACT_APP_FIREBASE_STORAGE_BUCKET=your_firebase_storage_bucket
        REACT_APP_FIREBASE_MESSAGING_SENDER_ID=your_firebase_messaging_sender_id
        REACT_APP_FIREBASE_APP_ID=your_firebase_app_id
        # Add REACT_APP_FIREBASE_MEASUREMENT_ID if needed
        ```
    *   Ensure other necessary configuration (like API endpoints if applicable) is set.

### Running Locally

1.  Start the development server:
    ```bash
    cd frontend-new
    npm start
    ```
2.  Open your browser to `http://localhost:3000` (or the configured port).

## Contributing

Contributions that align with the core principles (enhancing generic capabilities, improving AI interaction, refining patterns) are welcome. Please avoid submitting features that introduce domain-specific logic.

## License

MIT License. 